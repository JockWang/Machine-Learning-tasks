# 第6章 支持向量机

[TOC]

![img](https://uploader.shimo.im/f/6FIhgsGVcUMdrH8X.jpg!thumbnail)

## 间隔与支持向量

给定训练样本集，分类学习最基本的想法就是基于训练集在样本空间找到一个划分超平面，将不同类别的样本分开。如图所示：

![img](./pic/3.png)

在样本空间中，划分超平面可通过如下线性方程描述：
$$
w^Tx + b = 0
$$
其中$w$是法向量，决定超平面的方向，$b$为位移项，决定超平面与远点之间的距离。样本任意点$x$到超平面的距离可写为：
$$
\
r=\frac{\left|\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}+b\right|}{\|\boldsymbol{w}\|}
$$
如果超平面能够正确分类，则有
$$
\left\{\begin{array}{ll}{\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+b \geqslant+1,} & {y_{i}=+1} \\ {\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}_{i}+b \leqslant-1,} & {y_{i}=-1}\end{array}\right.
$$
如图，距离超平面最近的几个训练样本的使上式的等号成立，它们被称为**支持向量**（support vector），两个异类支持向量到超平面的距离之和为**间隔**（margin）。
$$
\gamma=\frac{2}{\|\boldsymbol{w}\|}
$$
![img](./pic/4.png)

我们项找到**最大间隔**来划分超平面

![img](./pic/5.png)

对于任意训练样本$(x_i,y_i)$，总有$\alpha_i = 0$或$y_if(x_i) = 1$。若$\alpha_i  = 0$，则样本不会在$f(x)$求和中出现，即不会对$f(x)$有影响；若$\alpha_i > 0$，则必有$y_if(x_i) = 1$ ，则该样本点位于最大间隔边界上，是一个支持向量。**支持向量机的重要性质：训练完成后，大部分的训练样本都不需保留，最终模型仅与支持向量有关。**

